save_path: "/network/projects/_groups/ecosystem-embeddings/exp/ckpt"
load_ckpt : ""
#log the experiment to comet ? 
log_comet: true
save_preds_path: ""
#overfit batches (for debugging)
overfit_debug: false
#number of batches to overfit on 
overfit_batches: 0

#use location ?
loc:
  use: false
  #if false, loc network and image network are trained separately and the output multipliesd as in the geopriors paper.
  #else, we concatenate features from the two subnetworks and a part is trained jointly
  concat: false
  #use elevation data for z in location (for now, leave as False, until elevation data is integrated)
  elev: false
  #take into account number of available checklists at a hotspot (leave False for now)
  num_checklists: false
  
comet:
  project_name: "env_ecosystem" #"ecosystem-duck"
  tags: ["test_run"]

experiment:
  task: "ebird_classifier"
  name: "ebird_classifier"
  seed: 42

  module:
    model: "resnet18"
    pretrained: True
    init_bias: "means"
    means_path: "/network/scratch/t/tengmeli/scratch/ecosystem-embedding/training/means_all_species.npy"
    lr: 0.001


optimizer: "SGD"  #"Adam"

scheduler: 
  name: "StepLR" #"ReduceLROnPlateau" #"ReduceLROnPlateau" #or "StepLR" "WarmUp"
  reduce_lr_plateau:
    factor: 0.1
    lr_schedule_patience: 5
  step_lr:
    step_size: 10 
    gamma: 0.5
  warmup:
    warmup_epochs: 10
    max_epochs: 200 
  cyclical:
    warmup_epochs: 10

variables: &default_vars
    ped_means: &ped_means [2230.56361696, 1374.68551614,   20.45478794,   19.04921312,
         31.1196319 ,   61.24246466,   36.68711656,   44.25620165]
    ped_std: &ped_std [2355.3843699 ,  107.88685009,    8.71958154,    6.69679905,
         23.66400261,    8.79233844,    9.91992735,   13.1028541 ]
    bioclim_means: &bioclim_means [ 11.99430391,  12.16226584,  36.94248176, 805.72045945,
        29.4489089 ,  -4.56172133,  34.01063026,  15.81641269,
         7.80845219,  21.77499491,   1.93990004, 902.9704986 ,
       114.61111788,  42.0276728 ,  37.11493781, 315.34206997,
       145.09703767, 231.19724491, 220.06619529]
    bioclim_std: &bioclim_std [  4.62661648,   2.31306195,   8.73155144, 220.15217856,
         3.66556263,   6.94077974,   6.73345032,   7.90953848,
        10.58786476, 3.71622992,   6.67059767, 372.85954139,
        49.59671974,  28.9984291 ,  25.76078507, 138.92188873,
        93.54401194, 130.66050149, 143.05699293]

data:
  loaders:
    num_workers: 4
    batch_size: 8
  #What kind of satellite input ? "refl" for "raw" reflectance values or "img" for 0-255 values (only supported for "rgb" and "nir" bands)
  datatype: "refl" 
  
  bands: ["r", "g", "b", "nir"]
  res: 10 
  
  env: ["ped", "bioclim"] #["ped", "bioclim"] #"all" "ped" or "bioclim"
  ped: 
      #pedological rasters
      res: 250
  bioclim: 
      #bioclim 
      res: 1000
  files:
    base: "/network/scratch/t/tengmeli/scratch/ecosystem-embedding/training/"
    train: "train_june_vf.csv"
    val: "val_june_vf.csv"
    test: "test_june_vf.csv"
    correction: "/network/scratch/t/tengmeli/scratch/ecosystem-embedding/training/correction_factor_final.pkl"
    correction_thresh: '/network/scratch/a/amna.elmustafa/tmp/ecosystem-embedding/data_processing/Htest.npy'
  correction_factor:
     use: None   #choises [None, 'before' (before sigmoid) ,'after'(after sigmoid)]
     thresh : True


  target:
    type: "probs"  #binary or probs
    # choose subset of birds : "ducks" for trying on species [37] or "songbirds" (307 species) or None (full set 684 species)
    subset: "not_songbirds"
 
  #normalization: None
  transforms:
    - name: matchres
      ignore: false
      target_size: [64, 64]
      
    - name: crop
      ignore: false
      p: 1
      ignore_band: ["bioclim", "ped"]
      center: true # disable randomness, crop around the image's center
      height: 64
      width: 64
    - name: resize
      ignore: false
      size: [256,256]
    - name: hflip
      ignore: "val"
      p: 0.5
    - name: vflip
      ignore: "val"
      p: 0.5
    - name: normalize
      ignore: false
      maxchan: false
      subset: ["sat"]
      custom: [[894.6719, 932.5726,693.2768, 2817.9849],[883.9763,747.6857,749.3098, 1342.6334]]
      #ImageNet values 
      #[[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]
      
      #Mean-std computed on training set
      #[[894.6719, 932.5726,693.2768], [883.9763,747.6857,749.3098]]
      #[894.6719, 932.5726,693.2768, 2817.9849], [883.9763,747.6857,749.3098, 1342.6334]
    - name: normalize
      ignore: false
      maxchan: false
      subset: ["bioclim"]
      custom: [*bioclim_means, *bioclim_std]
    - name: normalize
      ignore: false
      maxchan: false
      subset: ["ped"] #soil data
      custom: [*ped_means, *ped_std]
    - name: randomnoise
      ignore: True #false
      std: 0.01
      max_noise: 0.05
      
  total_species: 684
    
program: # These are the arguments that define how the train.py script works
  seed: 1337
  output_dir: output
  data_dir: data
  log_dir: logs
  overwrite: False
  
losses:
#scale attribute is just for plotting if the values are very small 

  criterion: "CrossEntropy" #or MAE or MSE  (loss to choosefor optim )
  ce:
    ignore: False
      #weights on the cross entropy
    lambd_pres: 1
    lambd_abs: 1
  metrics:
    - name: ce
      ignore: False
      #weights on the cross entropy
      lambd_pres: 1
      lambd_abs: 1
      scale : 1
    - name: mae
      ignore: False
      scale: 10
    - name: mse
      ignore: False
      scale: 10
    - name: topk
      ignore: False
      scale: 1
    - name: r2
      ignore: True #False
      scale: 1
    - name: kl
      ignore: False
      scale : 1
    - name: accuracy
      ignore: True
      scale: 1

        
# The values here are taken from the defaults here https://pytorch-lightning.readthedocs.io/en/1.3.8/common/trainer.html#init
# this probably should be made into a schema, e.g. as shown https://omegaconf.readthedocs.io/en/2.0_branch/structured_config.html#merging-with-other-configs
trainer: # These are the parameters passed to the pytorch lightning Trainer object
  logger: True
  checkpoint_callback: True
  callbacks: null
  default_root_dir: null
  gradient_clip_val: 0.0
 # gradient_clip_algorithm: "norm"
  process_position: 0
  num_nodes: 1
  num_processes: 1
  gpus: 1
  auto_select_gpus: False
  tpu_cores: null
  log_gpu_memory: null
  progress_bar_refresh_rate: null
  overfit_batches: 0.0
  track_grad_norm: -1
  check_val_every_n_epoch: 1
  fast_dev_run: False
  accumulate_grad_batches: 1
  max_epochs: 300
  min_epochs: null
  max_steps: null
  min_steps: null
  #max_time: null
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  limit_predict_batches: 1.0
  val_check_interval: 1.0
  flush_logs_every_n_steps: 100
  log_every_n_steps: 1
  accelerator: null
  sync_batchnorm: False
  precision: 32 #32
  weights_summary: "top"
  weights_save_path: null
  num_sanity_val_steps: 2
  #truncated_bptt_steps: null
  resume_from_checkpoint: null
  profiler: null
  benchmark: False
  deterministic: False
  reload_dataloaders_every_epoch: False
  auto_lr_find: False
  replace_sampler_ddp: True
  terminate_on_nan: False
  auto_scale_batch_size: True
  prepare_data_per_node: True
  plugins: null
  amp_backend: "native"
  #amp_level: "O2"
  #distributed_backend: null
  move_metrics_to_cpu: False
  multiple_trainloader_mode: "max_size_cycle"
  stochastic_weight_avg: False
