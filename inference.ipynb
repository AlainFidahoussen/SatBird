{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "sys.path.append(str(Path().resolve().parent.parent))\n",
    "\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from src.trainer.trainer import EbirdTask, EbirdDataModule\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from typing import Any, Dict, Tuple, Type, cast\n",
    "from src.dataset.utils import set_data_paths\n",
    "import pdb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf = OmegaConf.load(\"./configs/defaults.yaml\")\n",
    "config_fn = \"./configs/custom_meli-Copy1.yaml\"\n",
    "\n",
    "if os.path.isfile(config_fn):\n",
    "    user_conf = OmegaConf.load(config_fn)\n",
    "    conf = OmegaConf.merge(conf, user_conf)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"config_file={config_fn} is not a valid file\")\n",
    "\n",
    "conf = set_data_paths(conf)\n",
    "conf = cast(DictConfig, conf)  # convince mypy that everything is alright\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a bird\n",
    "with open('/network/scratch/t/tengmeli/ecosystem-embedding/species_list.txt', encoding=\"utf-8\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "indices = np.load('/network/scratch/t/tengmeli/ecosystem-embedding/songbirds_idx.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/network/scratch/t/tengmeli/ecosystem-embedding/songbirds.txt', encoding=\"utf-8\") as f:\n",
    "    song= f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = np.array(sorted(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "humming = 'Agelaius phoeniceus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3]),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(song) ==humming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([160]),)\n"
     ]
    }
   ],
   "source": [
    "humming ='Centronyx bairdii'\n",
    "i =np.where(np.array(lines) == humming)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =np.where(np.array(song) == humming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Custom CE Loss\n"
     ]
    }
   ],
   "source": [
    "task = EbirdTask(conf)\n",
    "datamodule = EbirdDataModule(conf)\n",
    "trainer_args = cast(Dict[str, Any], OmegaConf.to_object(conf.trainer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(conf.data.files.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(conf.data.files.val)\n",
    "len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.dataloader import get_path\n",
    "from src.dataset.utils import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(df, index):\n",
    "    meta = load_file(get_path(df, index, \"meta\"))\n",
    "    return(meta)\n",
    "\n",
    "def get_img(df, index):\n",
    "    band_npy = load_file(get_path(df, index, \"rgb\"))\n",
    "    return (band_npy)\n",
    "\n",
    "def get_img(df, index, new_width = 256, new_height = 256):\n",
    "    band_npy = load_file(get_path(df, index, \"rgb\"))\n",
    "   \n",
    "    im = Image.fromarray(np.transpose(band_npy, (1,2,0)))\n",
    "    width, height = im.size   # Get dimensions\n",
    "\n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    im = im.crop((left, top, right, bottom))\n",
    "    return(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./ckpt/songbird_smallimg64/epoch=212-step=204905.ckpt\"\n",
    "\n",
    "state_dict = torch.load(PATH)[\"state_dict\"]\n",
    "\n",
    "for key in list(state_dict.keys()):\n",
    "    state_dict[key.replace('model.', '')] = state_dict.pop(key)\n",
    "\n",
    "\n",
    "task.model.load_state_dict(state_dict)\n",
    "task.model.eval()\n",
    "m = nn.Sigmoid()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/t/tengmeli/.conda/envs/ebird-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup()\n",
    "test_dataloader = datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(batch, model):\n",
    "    x = batch['sat'].squeeze(1).to(device)\n",
    "    y = batch['target'].to(device)\n",
    "    y_hat = model(x)\n",
    "    pred = m(y_hat)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = []\n",
    "squares = []\n",
    "hs= []\n",
    "acc = []\n",
    "sum_ = torch.empty((0,305))\n",
    "for batch in test_dataloader:\n",
    "    pred = infer(batch, task.model).detach().cpu()\n",
    "    sum_  = torch.vstack([torch.abs(pred - batch['target']), sum_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([451, 305])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq = [276,   3, 130,  41,  62, 260,  96, 249, 205,  90,  71,  67, 261,\n",
    "       137, 231,  93, 154,  30, 295, 134, 254, 272, 161, 282, 187, 264,\n",
    "        26,  60, 141, 101, 292, 243, 257, 193, 165, 179, 240,  63, 211,\n",
    "       188,  97, 180, 213, 255, 262, 233, 248,  80, 271, 283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0340)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = sum_.mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0094)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((sum_)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1294), tensor(0.0371))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfmae = sum_[:, most_freq].mean()\n",
    "mfmse = ((sum_[:, most_freq])**2).mean()\n",
    "mfmae, mfmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = []\n",
    "squares = []\n",
    "hs= []\n",
    "acc = []\n",
    "for batch in test_dataloader:\n",
    "    pred = infer(batch, task.model)\n",
    "    #torch.abs(infer(a, task.model).detach().cpu() - a['target']).sum()\n",
    "    pred[pred>0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "    acc += [((pred.cpu()== batch[\"target\"]).sum(axis = 1))/305]\n",
    "    preds += [torch.abs(pred.cpu()- batch[\"target\"]).sum().item()]\n",
    "    \n",
    "    squares += [(torch.abs(pred.cpu()- batch[\"target\"])**2).sum().item()]\n",
    "    #for n, i in enumerate(pred):\n",
    "   #     i[i>0.5] = 1\n",
    "     #   preds += [i]\n",
    "    #    hs += batch[\"target\"][n]\n",
    "        #if i[idx] > 0.5 :\n",
    "         #   preds += [i[idx].item()]\n",
    "           # hs += [batch[\"hotspot_id\"][n]]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [np.array(a) for a in acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in acc:\n",
    "    for e in a:\n",
    "        accs.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9277598"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.sum(preds)/(451*350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.sum(squares)/(451*350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9377, 0.9246, 0.8951])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((pred.cpu()== batch[\"target\"]).sum(axis = 1))/305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs = []\n",
    "hst= []\n",
    "for batch in test_dataloader:\n",
    "    for c,i in enumerate(batch[\"original_target\"]):\n",
    "        if i[idx] > 0 :\n",
    "            targs += [i[idx].item()]\n",
    "            hst += [batch[\"hotspot_id\"][c]]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds), len(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds_[preds_>0.80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs_ = np.array(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs_ = targs_[targs_>0.80]\n",
    "len(targs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspots = [hs[i] for i in np.where(preds_[preds_>0.80])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_ = [hst[i] for i in np.where(targs_[targs_>0.80])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, hotspots = zip(*sorted(zip(predictions, hotspots),  reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, hotspots_t = zip(*sorted(zip(targs_, hst_), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df[\"hotspot\"] == \"L275497\"][\"rgb\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(df, hotspot, new_width = 256, new_height = 256):\n",
    "    band_npy = load_file(Path(test_df[test_df[\"hotspot\"] == hotspot][\"rgb\"].item()))\n",
    "   \n",
    "    im = Image.fromarray(np.transpose(band_npy, (1,2,0)))\n",
    "    width, height = im.size   # Get dimensions\n",
    "\n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    im = im.crop((left, top, right, bottom))\n",
    "    return(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(\"0.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,h in enumerate(list(hotspots_t)):\n",
    "    \n",
    "    im = get_img(test_df, h)\n",
    "    im.save(os.path.join(\"./predictions/agelaius/targets\" ,h + \"_\"+ str(targets[i]).replace(\".\",\"-\")+\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,h in enumerate(list(hotspots)):\n",
    "    im = get_img(test_df, h)\n",
    "    im.save(os.path.join(\"./predictions/agelaius/preds\" ,h + \"_\"+ str(predictions[i]).replace(\".\",\"-\")+ \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in hotspots if i not in hotspots_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in hotspots if i not in hotspots_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in hotspots_t if i not in hotspots])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds), len(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(hst) =='L3238822')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspots_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(batch):\n",
    "    x, y = batch\n",
    "    y_hat = model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    preds = ...\n",
    "    return {\"loss\": loss, \"other_stuff\": preds}\n",
    "\n",
    "\n",
    "def training_epoch_end(self, training_step_outputs):\n",
    "    all_preds = torch.stack(training_step_outputs)\n",
    "    ...\n",
    "The matching pseudocode is:\n",
    "\n",
    "outs = []\n",
    "for batch in train_dataloader:\n",
    "    # forward\n",
    "    out = training_step(val_batch)\n",
    "    outs.append(out)\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "training_epoch_end(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**trainer_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ebird-env)",
   "language": "python",
   "name": "ebird-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
